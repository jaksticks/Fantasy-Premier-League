{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_gameweek = 0\n",
    "shift_param = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import shap\n",
    "from pathlib import Path\n",
    "import datetime as dt\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model_training import cross_validation, optuna_objective_xgboost, plot_optuna_study, train_xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch data\n",
    "filepath = Path('../data/modeling/fpl_df.csv')\n",
    "fpl_df = pd.read_csv(filepath, index_col=0, low_memory=False)\n",
    "fpl_df['data_retrieved_datetime'] = pd.to_datetime(fpl_df['data_retrieved_datetime'])\n",
    "display(fpl_df.head())\n",
    "display(fpl_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpl_df.season.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_no_shift = ['element_type', 'home', 'opponent_xG_ewm_5', 'opponent_xG_ewm_10',\n",
    "       'opponent_xG_ewm_20', 'opponent_xG_ewm_40', 'opponent_xGA_ewm_5',\n",
    "       'opponent_xGA_ewm_10', 'opponent_xGA_ewm_20',\n",
    "       'opponent_xGA_ewm_40', ]\n",
    "\n",
    "features_shift = ['corners_and_indirect_freekicks_order', 'creativity_rank', \n",
    "       'direct_freekicks_order', 'ict_index_rank', 'influence_rank',\n",
    "       'minutes', 'now_cost', 'penalties_order', 'points_per_game', \n",
    "       'selected_by_percent', 'threat_rank',\n",
    "       'team_xG_ewm_5', 'team_xG_ewm_10', 'team_xG_ewm_20',\n",
    "       'team_xG_ewm_40', 'team_xGA_ewm_5', 'team_xGA_ewm_10',\n",
    "       'team_xGA_ewm_20', 'team_xGA_ewm_40', \n",
    "       'gameweek_assists_ewm_5', 'gameweek_bps_ewm_5',\n",
    "       'gameweek_creativity_ewm_5', 'event_points_ewm_5',\n",
    "       'gameweek_goals_scored_ewm_5', 'gameweek_goals_conceded_ewm_5',\n",
    "       'gameweek_saves_ewm_5', 'gameweek_threat_ewm_5',\n",
    "       'gameweek_xG_ewm_5', 'gameweek_xA_ewm_5', 'gameweek_xGA_ewm_5',\n",
    "       'gameweek_minutes_ewm_5', 'gameweek_xPoints_ewm_5',\n",
    "       'gameweek_assists_ewm_10', 'gameweek_bps_ewm_10',\n",
    "       'gameweek_creativity_ewm_10', 'event_points_ewm_10',\n",
    "       'gameweek_goals_scored_ewm_10', 'gameweek_goals_conceded_ewm_10',\n",
    "       'gameweek_saves_ewm_10', 'gameweek_threat_ewm_10',\n",
    "       'gameweek_xG_ewm_10', 'gameweek_xA_ewm_10', 'gameweek_xGA_ewm_10',\n",
    "       'gameweek_minutes_ewm_10', 'gameweek_xPoints_ewm_10',\n",
    "       'gameweek_assists_ewm_20', 'gameweek_bps_ewm_20',\n",
    "       'gameweek_creativity_ewm_20', 'event_points_ewm_20',\n",
    "       'gameweek_goals_scored_ewm_20', 'gameweek_goals_conceded_ewm_20',\n",
    "       'gameweek_saves_ewm_20', 'gameweek_threat_ewm_20',\n",
    "       'gameweek_xG_ewm_20', 'gameweek_xA_ewm_20', 'gameweek_xGA_ewm_20',\n",
    "       'gameweek_minutes_ewm_20', 'gameweek_xPoints_ewm_20',\n",
    "       'gameweek_assists_ewm_40', 'gameweek_bps_ewm_40',\n",
    "       'gameweek_creativity_ewm_40', 'event_points_ewm_40',\n",
    "       'gameweek_goals_scored_ewm_40', 'gameweek_goals_conceded_ewm_40',\n",
    "       'gameweek_saves_ewm_40', 'gameweek_threat_ewm_40',\n",
    "       'gameweek_xG_ewm_40', 'gameweek_xA_ewm_40', 'gameweek_xGA_ewm_40',\n",
    "       'gameweek_minutes_ewm_40', 'gameweek_xPoints_ewm_40',\n",
    "       'gameweek_assists_expanding', 'gameweek_bps_expanding',\n",
    "       'gameweek_creativity_expanding', 'event_points_expanding',\n",
    "       'gameweek_goals_scored_expanding',\n",
    "       'gameweek_goals_conceded_expanding', 'gameweek_saves_expanding',\n",
    "       'gameweek_threat_expanding', 'gameweek_xG_expanding',\n",
    "       'gameweek_xA_expanding', 'gameweek_xGA_expanding',\n",
    "       'gameweek_minutes_expanding', 'gameweek_xPoints_expanding',\n",
    "       'gameweek_assists_expanding_per90', 'gameweek_bps_expanding_per90',\n",
    "       'gameweek_creativity_expanding_per90',\n",
    "       'event_points_expanding_per90',\n",
    "       'gameweek_goals_scored_expanding_per90',\n",
    "       'gameweek_goals_conceded_expanding_per90',\n",
    "       'gameweek_saves_expanding_per90',\n",
    "       'gameweek_threat_expanding_per90', 'gameweek_xG_expanding_per90',\n",
    "       'gameweek_xA_expanding_per90', 'gameweek_xGA_expanding_per90',\n",
    "       'gameweek_xPoints_expanding_per90', 'xG_overperformance'\n",
    "    ]\n",
    "\n",
    "target = ['event_points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift given features\n",
    "df = fpl_df.copy()\n",
    "df[features_shift] = df.groupby(['first_name', 'second_name'])[features_shift].shift(shift_param)\n",
    "display(df.head())\n",
    "display(df.tail())\n",
    "display(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum(axis=1).plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows where too much data missing\n",
    "df = df[df.isnull().sum(axis=1) <= 90].reset_index(drop=True)\n",
    "display(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = df[~(df.data_retrieved_datetime>'1-1-2024')].index\n",
    "display(train_index)\n",
    "test_index = df[(df.data_retrieved_datetime>'1-1-2024')].index\n",
    "display(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features_no_shift+features_shift].copy()\n",
    "y = df[target].copy()\n",
    "X_train = df.loc[train_index, features_no_shift+features_shift].copy()\n",
    "y_train = df.loc[train_index, target].copy()\n",
    "X_test = df.loc[test_index, features_no_shift+features_shift].copy()\n",
    "y_test = df.loc[test_index, target].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna_bounds = {}\n",
    "optuna_bounds['learning_rate'] = [0.001, 0.1]\n",
    "optuna_bounds['max_depth'] = [4, 10]\n",
    "optuna_bounds['min_child_weight'] = [0.01, 1]\n",
    "optuna_bounds['gamma'] = [0, 0.5]\n",
    "optuna_bounds['subsample'] = [0.5, 1]\n",
    "optuna_bounds['colsample_bytree'] = [0.5, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose max number of trials for optimization\n",
    "n_optimization_trials = 200\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(\n",
    "    lambda trial: optuna_objective_xgboost(trial, optuna_bounds, X_train, y_train),\n",
    "    n_trials=n_optimization_trials,\n",
    "    )\n",
    "\n",
    "plot_optuna_study(study)\n",
    "\n",
    "print('Best params:')\n",
    "print(study.best_params)\n",
    "print('Test logloss for best params:')\n",
    "print(study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find nr_estimators for best params (here test-logloss-mean is the average log-loss in cross-validation test)\n",
    "cv_df = cross_validation(X_train, y_train, study.best_params)\n",
    "n_estimators = cv_df.sort_values(f'test-rmse-mean').index[0] + 1\n",
    "cv_df[['train-rmse-mean', 'test-rmse-mean']].plot();\n",
    "print(f'Number of estimators: {n_estimators}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = study.best_params\n",
    "xgb_params['n_estimators'] = int(n_estimators)\n",
    "\n",
    "model, results = train_xgboost(xgb_params, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = xgb_params.copy()\n",
    "results_dict['train_rmse'] = results['train_rmse']\n",
    "results_dict['test_rmse'] = results['test_rmse']\n",
    "results_dict['train_r2'] = results['train_r2']\n",
    "results_dict['test_r2'] = results['test_r2']\n",
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(model.predict, X_train)\n",
    "shap_values = explainer(X_train.sample(2000, random_state=42))\n",
    "shap.plots.bar(shap_values, max_display=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model with full data and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, results = train_xgboost(xgb_params, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(model.predict, X)\n",
    "shap_values = explainer(X.sample(2000, random_state=42))\n",
    "shap.plots.bar(shap_values, max_display=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE MODEL AND RESULTS \n",
    "time_stamp = str(dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "# save model as pickle file\n",
    "pickle.dump(model, open(f\"../models/xgboost_{time_stamp}.pkl\", 'wb'))\n",
    "\n",
    "# save results\n",
    "results_path = Path(f'../training_results/xgboost_{time_stamp}.json')\n",
    "with open(results_path, 'w') as json_file:\n",
    "    json.dump(results_dict, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Shap analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goalkeepers\n",
    "explainer = shap.Explainer(model.predict, X)\n",
    "shap_values = explainer(X[X.element_type==1]) #.sample(2000, random_state=42)\n",
    "shap.plots.bar(shap_values, max_display=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc: Model performance check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_folder = 'season24_25'\n",
    "model_file_name = 'xgboost_20240813-184939.pkl'\n",
    "path = Path(f'../models/{model_file_name}')\n",
    "model = pickle.load(open(path, 'rb'))\n",
    "display(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "y_predicted = model.predict(X_train)\n",
    "\n",
    "# measure performance\n",
    "rmse_train = root_mean_squared_error(y_train, y_predicted)\n",
    "print(f'RMSE (train): {rmse_train}')\n",
    "r2_train = r2_score(y_train, y_predicted)\n",
    "print(f'R^2 (train): {r2_train}')\n",
    "\n",
    "# predictions\n",
    "y_predicted = model.predict(X_test)        \n",
    "\n",
    "# measure performance\n",
    "rmse_test = root_mean_squared_error(y_test, y_predicted)\n",
    "print(f'RMSE (test): {rmse_test}')\n",
    "r2_test = r2_score(y_test, y_predicted)\n",
    "print(f'R^2 (test): {r2_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv23-24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
